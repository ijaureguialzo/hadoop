version: '3.5'

services:

  https-portal:
    image: steveltn/https-portal:1
    container_name: https-portal
    environment:
      DOMAINS: >
        namenode -> http://namenode:9870,
        datanode1 -> http://datanode1:9864,
        datanode2 -> http://datanode2:9864,
        resourcemanager -> http://resourcemanager:8088,
        nodemanager -> http://nodemanager:8042,
        historyserver -> http://historyserver:8188,
      STAGE: local
    volumes:
      - https-portal_certs:/var/lib/https-portal
    ports:
      - 80:80
      - 443:443
    depends_on:
      - namenode
      - datanode1
      - datanode2
      - resourcemanager
      - nodemanager
      - historyserver
    networks:
      main:
        ipv4_address: 172.27.10.1

  namenode:
    image: bde2020/hadoop-namenode:${HADOOP_VERSION}
    container_name: namenode
    hostname: namenode
    volumes:
      - namenode_data:/hadoop/dfs/name
      - ./ficheros:/ficheros
    environment:
      - CLUSTER_NAME=test
    env_file:
      - ./hadoop.env
    expose:
      - 9870
    ports:
      - 8020:8020
    networks:
      main:
        ipv4_address: 172.27.20.1

  resourcemanager:
    image: bde2020/hadoop-resourcemanager:${HADOOP_VERSION}
    container_name: resourcemanager
    hostname: resourcemanager
    environment:
      SERVICE_PRECONDITION: "namenode:9870 datanode1:9864 datanode2:9864"
    env_file:
      - ./hadoop.env
    expose:
      - 8088
    ports:
      - 8088:8088
    depends_on:
      - namenode
      - datanode1
      - datanode2
    networks:
      main:
        ipv4_address: 172.27.20.2
    restart: on-failure
    healthcheck:
      disable: true

  nodemanager:
    image: bde2020/hadoop-nodemanager:${HADOOP_VERSION}
    container_name: nodemanager
    hostname: nodemanager
    environment:
      SERVICE_PRECONDITION: "namenode:9870 datanode1:9864 datanode2:9864 resourcemanager:8088"
    env_file:
      - ./hadoop.env
    expose:
      - 8042
    depends_on:
      - namenode
      - datanode1
      - datanode2
      - resourcemanager
    networks:
      main:
        ipv4_address: 172.27.20.3

  historyserver:
    image: bde2020/hadoop-historyserver:${HADOOP_VERSION}
    container_name: historyserver
    hostname: historyserver
    environment:
      SERVICE_PRECONDITION: "namenode:9870 datanode1:9864 datanode2:9864 resourcemanager:8088"
    volumes:
      - historyserver_data:/hadoop/yarn/timeline
    env_file:
      - ./hadoop.env
    expose:
      - 8188
    depends_on:
      - namenode
      - datanode1
      - datanode2
      - resourcemanager
    networks:
      main:
        ipv4_address: 172.27.20.4

  datanode1:
    image: bde2020/hadoop-datanode:${HADOOP_VERSION}
    container_name: datanode1
    hostname: datanode1
    volumes:
      - datanode1_data:/hadoop/dfs/data
      - ./ficheros:/ficheros
    env_file:
      - ./hadoop.env
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
      HDFS_CONF_dfs_datanode_address: "0.0.0.0:7001"
      HDFS_CONF_dfs_datanode_ipc_address: "0.0.0.0:7101"
    depends_on:
      - namenode
    expose:
      - 9864
    ports:
      - 7001:7001
      - 7101:7101
    networks:
      main:
        ipv4_address: 172.27.100.1

  datanode2:
    image: bde2020/hadoop-datanode:${HADOOP_VERSION}
    container_name: datanode2
    hostname: datanode2
    volumes:
      - datanode2_data:/hadoop/dfs/data
      - ./ficheros:/ficheros
    env_file:
      - ./hadoop.env
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
      HDFS_CONF_dfs_datanode_address: "0.0.0.0:7002"
      HDFS_CONF_dfs_datanode_ipc_address: "0.0.0.0:7102"
    depends_on:
      - namenode
    expose:
      - 9864
    ports:
      - 7002:7002
      - 7102:7102
    networks:
      main:
        ipv4_address: 172.27.100.2

networks:
  main:
    ipam:
      driver: default
      config:
        - subnet: 172.27.0.0/16

volumes:
  https-portal_certs:
  namenode_data:
  datanode1_data:
  datanode2_data:
  historyserver_data:
